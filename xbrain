#!/usr/bin/env python
"""
xbrain is a tool for relating non-neural scores and MRI data features.

Usage:
    xbrain [options] <database>

Arguments:
    <database>      a .csv file containing MRI data (X) and non-neural data (y)

Options:
    --xcorr=TS             A list of timeseries for intersubject correlations.
    --connectivity=CONN    A list of timeseries for static connectivity.
    --dynamics=DYNA        A list of timeseries for dynamic connectivity.
    --statmaps=STATS       A list of statmaps .nii.gz (3D) predictors.
    --raw=RAW              A list of column names in database as predictors.
    --biotype-conn=BIOC    A list of timeseries for biotyping using static connectivity.
    --biotype-xcorr=BIOX   A list of timeseries for biotyping using intersubject correlations.
    --biotype-stats=BSTAT  A list of statmaps .nii.gz (3D) predictors.
    --biotype-n=N          Number of biotypes to find (optional: can be done automatically).
    --predict=PREDICT      A list of column names in database to predict.
    --covariates=COV       A list of column names in database to regress from X.
    --group-column=COL     Column of group names.
    --standardize          Z-scores all variables in y.
    --standardize-group=G  Z-scores all variables in y by this group from group-column.
    --roi-mask=MASK        A ROI NIFTI file.
    --biotype-model=MDL    A biotype model (.npz) file generated by xbrain.
    --k=K                  Number of cross-validation folds [default: 10]
    --iterations=N         Number of times to repeat full procedure [default: 1]
    --select=SELECT        Retain this many features pre training (defined as a proportion of the number of samples). [default: 0]
    --method=METHOD        One of "multiclass", "target", "ysplit", "anomaly".
    --y-cutoff=CUTOFF      % cutoff to find low and high y group. [default: 0.5]
    --target-group=GROUP1  Draw the xbrain template and standardize y from this group.
    --two-template=GROUP2  If defined, X is the difference between target-group and this group.
    --output=OUTPUT        A directory to place outputs.
    --shuffle_cca          Shuffles y randomly for CCA (biotyping only).
    --shuffle_y            Shuffles y randomly for control experiments.
    --diagnostics          Run diagnostics on input data.
    --debug                Verbose outputs.

DETAILS

The xbrain analysis uses a double-cross validation approach to demonstrate
whether the similarities in neural architecture or activity in the brain (X) is
predictive of non-neural variables of interest (y). For example, demographics
(AGE, SEX), cognitive scores (IQ, TASIT), or clinical variables (medications
taken, number of hospital visits in the last year).

** inputs **

<database> is a .csv spreadsheet containing predictor values (y) and paths to
input neuroimaging features (X). e.g.,

SUBJ,  IQ,   AGE,  TS_TASK1,                TS_TASK2
0001,  99,    24,  /path/to/0001_task1.csv, /path/to/0002_task2.csv
0002, 103,    45,  /path/to/0002_task1.csv, /path/to/0002_task2.csv
0003,  89,    32,  /path/to/0002_task1.csv, /path/to/0002_task2.csv

For X, xbrain accepts either 2D timeseries files in .csv format, 3D statmap
files in NIFTI format, raw databse entries (defined on a column wise basis), or
some combination of the above. All inputs can be submitted at comma seperated
lists of inputs, e.g., --xcorr='ts_task1,ts_task2', with 'ts_task1' referring to
a column in <database>.

If a 3D statmap is submitted, a ROI mask of the same dimensions must also be
submitted, and this mask should have the same number of unique ROIs as there are
in the submitted timeseries data. The average value will be taken from each ROI
and added to the feature matrix X.

For y, xbrain accepts either categorical or continuous data. Any column of y
that contains more than 9 unique entries is assumed to be continuous, otherwise
that data is treated as categorical by default.

** methods **

xbrain allows you to perform 4 kinds of classifiction experiments.

"multiclass": takes the predict column as group labels and attempts to build a
n-way classifier. Typically used to distinguish between multiple diagnostic or
treatment groups. xcorr template drawn from --target-group. --two-template can
be any other valid group.

"target": takes the predict column as group labels and sets the target group to
be group 1 (using --target-group), and all other labels to be group 0. Used to
simplify the classification problem (e.g., diagnosis vs. no-diagnosis). xcorr
template drawn from --target-group. If --two-template is defined, it is always
drawn fom group 0.

"ysplit": takes the predict column as a continuous cognitive score and splits it
into a low and high score group. If multiple columns are submitted, uses PCA to
extract the top PC and splits on this variable.  if y-cutoff is defined, splits
at the defined percentile. y-cutoff can be a list of percentiles, in which case
xbrain will test each. If y-cutoff is not defined, a median split is used (0.5).
If y-cutoff is "auto", uses a gaussian fit to guess what percentage of the data
in y are outliers.

"anomaly": takes the input features and attempts to find outliers using the X
data only (neuroimaging features). Then takes the input feature vector y and
looks for any statistical difference between the in-group and outlier group.

** outer loop: stratified sample k fold cross validation**

The sample population is split int K distinct folds (e.g., --k=5, or 5 folds).
This requires a large sample (< 70 subjects preferred), but k-fold cross
validation is more robust to major outliers, which are likely in heterogenous
psychiatric populations. Briefly, K-fold cross validation splits the population
into a test set (n/K) and training set (the remainder). For each fold,
cross-brain correlations are calculated for each individual against the
template drawn from the training population only, so there is complete
independence between the test set and the template population. The training data
is used to train a classifier to predict the non-neural variable of interest
using these cross brain correlations. The performance of the model is evaluated
against the test set, and performance measures are averaged across all folds.

**inner loop: hyperparamater cross validation**

randomized cross validation (3 folds per iteration, 100 iterations) is done to
test all hyperperameters on splits of the training data. The best model is
brought forward for testing. The hyperparameters for each model are defined in
xbrain.stats.classify.

**features**

The primary feature used is cross-brain correlation of fMRI time series, but
this tool will also accept 3D stat maps (i.e., GLM scores, FA). These can be
combined because for each subject, we collapse the timeseries down to a vector
of cross brain correlation values the same length as the number of ROIs.

In order to do this, a mask with nonzero ROIs must be supplied. The number of
nonzero ROIs must be the same as the number of timeseries supplied. The average
statistic from within each ROI will be taken as the feature for that ROI.

During training and testing, the cross brain correlation values and statistic
vectors will be concatenated. One must be careful not to add too many
features into the model, as this can lead to overfitting and poor
generalizability.

xbrain -h or --help prints this message.
"""

from copy import copy
import collections
import logging
import random
import shutil
import string
import sys, os

from scipy.stats import sem, mode
from sklearn.model_selection import KFold, StratifiedKFold
import numpy as np
import pandas as pd

from docopt import docopt
import correlate as corr
import stats as stats
import utils as utils

logging.basicConfig(level=logging.WARN, format="[%(name)s] %(levelname)s: %(message)s")
logger = logging.getLogger(os.path.basename(__file__))


def parse_results(results):
    """Parses results vector and returns mean & sem for test & train"""
    outputs = []
    n = len(results[0])

    for i in range(n):
        m = np.mean([result[i] for result in results])
        s = sem([result[i] for result in results])
        outputs.append((m, s))

    return(outputs)


def writer(csv, string):
    """write to the submitted csv if it is defined"""
    if csv:
        csv.writelines(string)


def assert_output(output):
    """handles output directory (folder creation, permissions checking)"""
    if output:
        logger.info('output directory: {}'.format(output))
        if not os.path.exists(output):
            try:
                os.makedirs(output)
            except:
                logger.error('failed to create output directory {}'.format(output))
                sys.exit(1)
    else:
        logger.info('no output specified, all outputs will be written to ${HOME}')
        output = os.path.expanduser('~')

    return output


def load_database(database):
    """attempts to load database file, exits if fails"""
    try:
        db = pd.read_csv(database)
    except:
        logger.error('failed to parse input .csv database {}'.format(database))
        sys.exit(1)

    return db


def main(arguments, output, iteration):

    # dataframe
    database      = arguments['<database>']

    # X
    xcorr         = arguments['--xcorr']
    connectivity  = arguments['--connectivity']
    dynamics      = arguments['--dynamics']
    statmaps      = arguments['--statmaps']
    raw           = arguments['--raw']
    roi_mask      = arguments['--roi-mask']
    covariates    = arguments['--covariates']

    # y
    predict       = arguments['--predict']
    standardize   = arguments['--standardize']
    stdgroup      = arguments['--standardize-group']
    y_cutoff      = arguments['--y-cutoff']
    target_group  = arguments['--target-group']
    groupcol      = arguments['--group-column']


    # biotype related inputs (for y)
    biotype_conn  = arguments['--biotype-conn']
    biotype_xcorr = arguments['--biotype-xcorr']
    biotype_stats = arguments['--biotype-stats']
    biotype_mdl   = arguments['--biotype-model']
    biotype_n     = arguments['--biotype-n']
    shuffle_cca   = arguments['--shuffle_cca']

    # xbrain methods
    method        = arguments['--method']
    two_template  = arguments['--two-template']
    diagnostics   = arguments['--diagnostics']

    # classification settings
    k             = int(arguments['--k'])
    select        = float(arguments['--select'])
    shuffle_y     = arguments['--shuffle_y']

    db = load_database(database)

    # stores output information for each iteration
    csv_info = open(os.path.join(output, 'xbrain_information_iter{}.csv'.format(
        str(iteration).zfill(2))), 'wb')
    csv_results = open(os.path.join(output, 'xbrain_results_iter{}.csv'.format(
        str(iteration).zfill(2))), 'wb')
    csv_hyper = open(os.path.join(output, 'xbrain_hyperparameters_iter{}.csv'.format(
        str(iteration).zfill(2))), 'wb')

    writer(csv_info, 'xbrain run with the following inputs\n  statmaps={}\n  xcorr={}\n  connectivity={}\n  dynamics={}\n  raw={}\n  predict={}\n'.format(
            statmaps, xcorr, connectivity, dynamics, raw, predict))

    # gather and reduce database to specified columns
    xcorr = utils.split_columns(xcorr)
    connectivity = utils.split_columns(connectivity)
    dynamics = utils.split_columns(dynamics)
    statmaps = utils.split_columns(statmaps)
    biotype_conn = utils.split_columns(biotype_conn)
    biotype_xcorr = utils.split_columns(biotype_xcorr)
    biotype_stats = utils.split_columns(biotype_stats)
    raw = utils.split_columns(raw)
    predict = utils.split_columns(predict)
    covariates = utils.split_columns(covariates)
    groupcol = utils.split_columns(groupcol)

    columns = []
    columns.append(db.columns[0]) # id column assumed

    variables = [xcorr, connectivity, dynamics, statmaps, biotype_conn,
        biotype_xcorr, biotype_stats, raw, predict, covariates, groupcol]

    for variable in variables:
        if variable:
            utils.assert_columns(db, variable)
            columns.extend(variable)

    columns = list(set(columns))
    db = db[columns]
    n_pre = len(db)
    db = db.dropna(axis=0)
    logger.debug('database cols: {}, rows remaining after clean: {}/{}'.format(
        columns, len(db), n_pre))
    writer(csv_info, 'options:\n  n={}\n  k={}\n'.format(len(db), k))

    logger.debug('generating dependent variable vector y')
    # if required, normalize y variables by the stdgroup's mean / std
    if groupcol:
        if len(groupcol) != 1:
            logger.error('Only one group column permitted.')
            sys.exit(1)
        group_labels = utils.gather_columns(db, groupcol)

    y = utils.gather_columns(db, predict)
    y_raw = copy(y)

    if standardize:
        if stdgroup:
            group_labels, stdgroup = stats.make_classes(group_labels, stdgroup)
            y = stats.standardize_by_group(y, group_labels, stdgroup)
        else:
            y = stats.standardize(y)

    # method: valid?
    if biotype_conn or biotype_xcorr:
        method = 'biotype'

    methods = ['multiclass', 'target', 'ysplit', 'anomaly', 'biotype']
    if method not in methods:
        logger.error('method {} invalid, pick from {}'.format(method, methods))
        sys.exit(1)
    writer(csv_info, '  method={}\n'.format(method))

    # biotype n: integer?
    if biotype_n:
        biotype_n = int(biotype_n)
        if biotype_n < 2:
            logger.error('number of biotypes to be found must be at least 2, recieved {}'.format(biotype_n))
            sys.exit(1)
        writer(csv_info, '  biotype-n={}\n'.format(biotype_n))

    # y_cutoff: percentile?
    if method == 'ysplit' and y_cutoff != 'auto':
        y_cutoff = float(y_cutoff)
        if not utils.is_probability(y_cutoff):
            logger.error('ysplit: target_cutoff percentile {} invalid, should be [0-1] or "auto"'.format(y_cutoff))
            sys.exit(1)
        writer(csv_info, '  y-cutoff={}\n'.format(y_cutoff))

    if target_group:
        target_group = int(target_group)
        writer(csv_info, '  target-group={}\n'.format(target_group))
    else:
        target_group = -1

    # two_template: valid?
    if method == 'anomaly' and two_template:
        logger.warning('anomaly mode does not allow for two template analysis, ignoring')
        two_template = -1
    if two_template:
        two_template = int(two_template)
        if two_template == target_group:
            logger.error('two_template group {} should be different than the target group {}'.format(two_template, target_group))
            sys.exit(1)
        writer(csv_info, '  target-group={}\n'.format(target_group))

    # preprocess y in prep for classification experiments
    if method != 'biotype':
        if len(y.shape) == 2 and y.shape[1] > 1:
            # compress y to 1d vector, if required (predicted_values)
            logger.info('using PCA to reduce {} dvs in y down to 1 component'.format(y.shape[0]))
            y = stats.pca_reduce(y)

        if method == 'ysplit':
            if y_cutoff == 'auto':
                # automatically determine values that fall outside of the normal
                # range by fitting a gaussian to y and looking for extreme values
                y = stats.find_outliers(y, output, n_sigma=1)
            else:
                # split y at a pre-defined percentile
                y = utils.make_dv_groups(y, y_cutoff)

        if method == 'anomaly':
            # automatically determine values that fall outside of the normal
            # range by fitting a gaussian to y and looking for extreme values
            y = stats.find_outliers(y, output)
        else:
            # split y at a pre-defined percentile
            y, target_group = stats.make_classes(y, target_group)

        if target_group >= 0:
            if target_group not in y:
                logger.error('target_group {} not in y: valid={}'.format(target_group, np.unique(y)))
                sys.exit(1)
        if two_template >= 0:
            if two_template not in y:
                logger.error('two template group {} not in y: valid={}'.format(two_template, np.unique(y)))
                sys.exit(1)

        # set y values of the target group to 1, and the rest to 0
        if method == 'target':
            if target_group < 0:
                logger.error('target_group undefined and method=target, exiting')
                sys.exit(1)
            y_tmp = np.zeros(y.shape)
            y_tmp[y == target_group] = 1
            y_tmp[y != target_group] = 0
            y = y_tmp

        # add a column with the preprocessed y groups
        y_preprocessed = ''.join(random.choice(string.ascii_uppercase) for _ in range(10))
        db[y_preprocessed] = y

    # list of tuples [(train1, test1), (train2, test2), ... (trainN, testN)]
    acc, rec, prec, f1, auc = [], [], [], [], []
    # dict of lists containing the best hyperparameter found for each fold
    hp_dict = collections.defaultdict(list)
    y_predictions = np.zeros(len(db)) # predictions from test sets
    y_actual = np.zeros(len(db)) # 'actual' values from test sets

    header = ','.join([
        'k', 'accuracy_train', 'accuracy_test',
        'recall_train_macro', 'recall_test_macro', 'recall_train_micro', 'recall_test_micro',
        'precision_train_macro', 'precision_test_macro', 'precision_train_micro', 'precision_test_micro',
        'f1_train_macro', 'f1_test_macro', 'f1_train_micro', 'f1_test_micro',
        'auc_train_macro', 'auc_test_macro', 'auc_train_micro', 'auc_test_micro',
        'n_features_retained\n'])
    writer(csv_results, header)

    # below are outside k-fold b/c no info shared between samples
    if covariates:
        X_cov = utils.gather_columns(db, covariates)

    if connectivity:
        X_conn = corr.calc_connectivity(db, connectivity)
        X_conn = utils.clean(X_conn)
        if covariates:
            X_conn = stats.covary(X_conn, X_cov)

    if statmaps:
        X_stat = utils.gather_stats(db, statmaps, roi_mask)
        X_stat = utils.clean(X_stat)
        if covariates:
            X_stat = stats.covary(X_stat, X_cov)

    if raw:
        X_raw = utils.gather_columns(db, raw)
        X_raw = utils.clean(X_raw)
        if covariates:
            X_raw = stats.covary(X_raw, X_cov)

    if method == 'biotype':

        # collect complete biotyping data
        if biotype_conn:
            X_bio_conn = corr.calc_connectivity(db, biotype_conn)
        if biotype_xcorr:
            X_bio_xcorr = corr.calc_xbrain(db, db, biotype_xcorr)  # no template groups
        if biotype_stats:
            X_bio_stats = utils.gather_stats(db, biotype_stats, roi_mask)

        for features in ['X_bio_xcorr', 'X_bio_conn', 'X_bio_stats']:
            if features in vars():
                if 'X_bio' in vars():
                    X_bio = np.hstack((X_bio, eval(features)))
                else:
                    X_bio = eval(features)

        X_bio = utils.clean(X_bio)
        if covariates:
            X_bio = stats.covary(X_bio, X_cov)

        # load the results of a previous run
        if biotype_mdl:
            try:
                logger.info('loading biotype model from {}'.format(biotype_mdl))
                biotype_mdl = utils.load_biotype(biotype_mdl)
            except Exception as e:
                logger.error('error loading biotype model {}\n{}'.format(biotype_mdl, e))
                sys.exit(1)

        # biotype the full sample
        elif shuffle_cca:
            biotype_mdl = stats.estimate_biotypes(X_bio, y, predict, output, k=biotype_n, shuffle=True)
        else:
            biotype_mdl = stats.estimate_biotypes(X_bio, y, predict, output, k=biotype_n)

        # save the biotypes in the database (for post hoc analysis)
        db['biotype'] = biotype_mdl['clusters']

        # plot details about the loaded model
        stats.plot_biotype_X_scatter(biotype_mdl, os.path.join(output, 'xbrain_biotype_X_scatter.pdf'))
        stats.plot_biotype_y_loadings(biotype_mdl, os.path.join(output, 'xbrain_biotype_y_loadings.pdf'))
        stats.plot_biotype_cluster_scores(biotype_mdl, os.path.join(output, 'xbrain_biotype_cluster_scores.pdf'))

        # for each X input column product one nifti file of loadings
        if biotype_conn and roi_mask:
            for column in biotype_conn:
                X_tmp = corr.calc_connectivity(db, [column])
                stats.plot_biotype_X_conn_loadings(biotype_mdl, X_tmp, roi_mask,
                    os.path.join(output, 'xbrain_biotype_X_conn_loadings_{}.nii.gz'.format(column)))
        if biotype_xcorr and roi_mask:
            for column in biotype_xcorr:
                X_tmp = corr.calc_xbrain(db, db, [column])
                stats.plot_biotype_X_stat_loadings(biotype_mdl, X_tmp, roi_mask,
                    os.path.join(output, 'xbrain_biotype_X_xcorr_loadings_{}.nii.gz'.format(column)))
        if biotype_stats and roi_mask:
            for column in biotype_stats:
                X_tmp = utils.gather_stats(db, [column], roi_mask)
                stats.plot_biotype_X_stat_loadings(biotype_mdl, X_tmp, roi_mask,
                    os.path.join(output, 'xbrain_biotype_X_stat_loadings_{}.nii.gz'.format(column)))

    if k > len(db):
        k = len(db) # leave one out cross validation

    # for biotyping, we don't know who the groups are yet, so we can't stratify
    if method == 'biotype' or k == len(db):
        logger.info('Outer Loop: {} fold cross validation'.format(k))
        kf = KFold(n_splits=k, shuffle=True)
    else:
        logger.info('Outer Loop: {} fold stratified cross validation'.format(k))
        kf = StratifiedKFold(n_splits=k, shuffle=True)

    count = 1
    for train_idx, test_idx in kf.split(np.zeros(y.shape[0]), y):

        y_train = y[train_idx]
        y_test = y[test_idx]

        # biotyping: use CCA, clustering, LDA to calculate y for test and train
        if method == 'biotype':
            X_bio_train = X_bio[train_idx, :]
            X_bio_test = X_bio[test_idx, :]
            if shuffle_cca:
                y_train, y_test = stats.biotype(X_bio_train, X_bio_test, y_train, biotype_mdl, shuffle=True)
            else:
                y_train, y_test = stats.biotype(X_bio_train, X_bio_test, y_train, biotype_mdl)

            # add a column with the preprocessed y groups
            y_preprocessed_data = np.zeros(y.shape[0])
            y_preprocessed_data[train_idx] = y_train
            y_preprocessed_data[test_idx] = y_test
            y_preprocessed = ''.join(random.choice(string.ascii_uppercase) for _ in range(10))
            db[y_preprocessed] = y_preprocessed_data

        # cross-brain correlations: calculate X_xcorr from a training templates
        if xcorr:
            # calculate cross brain correlations with the target group only
            if target_group >= 0:
                logger.debug('xcorr: calculating template 1 (target_group={})'.format(target_group))
                template_1 = corr.find_template(db.iloc[train_idx], y_preprocessed, xcorr, group=target_group)
            # calculate cross brain correlations with the entire training sample
            else:
                logger.debug('xcorr: calculating template 1')
                template_1 = corr.find_template(db.iloc[train_idx], y_preprocessed, xcorr)
            X_xcorr = corr.calc_xbrain(template_1, db, xcorr)

            # create a second X from the second target group defined, subtract
            if two_template >= 0:
                logger.debug('xcorr: calculating template 2 (group {})'.format(two_template))
                template_2 = corr.find_template(db.iloc[train_idx], y_preprocessed, xcorr, group=two_template)
                X2_xcorr = corr.calc_xbrain(template_2, db, xcorr)
                logger.info('xcorr: two template analysis (group {} - group {})'.format(target_group, two_template))
                X_xcorr = X_xcorr - X2_xcorr


        # dynamic connectivity: calculate group-wise states from training data
        if dynamics:

            win_length = config['dynamics']['win_length']
            win_step = config['dynamics']['win_step']

            # loop through groups to get states for each group independently
            groups = np.unique(y_train)
            all_states = []
            for i, group in enumerate(groups):

                # last two parameters: win_length, win_step (both in TRs)
                logger.debug('dynamics: calculating states for group {}'.format(group))
                train_idx_subset = train_idx[np.where(y_train == group)[0]]
                # TODO: work in covariate regression step here!!
                d_rs_group = corr.calc_dynamic_connectivity(db.iloc[train_idx_subset], dynamics, win_length, win_step)
                d_rs_group[np.isnan(d_rs_group)] = 0
                d_rs_group[np.isinf(d_rs_group)] = 0

                # use k means clustering to compute centroids (rois x states)
                group_states = stats.get_states(d_rs_group, k=config['dynamics']['n_states'])
                all_states.append(group_states)

            # combine states between groups
            states = np.hstack(all_states)

            # regress each subj against the states (clusters). X is beta coeffs
            all_coeffs = []
            for subj in np.arange(db.shape[0]):
                logger.debug('fitting states for subject {}'.format(subj))
                d_rs = corr.calc_dynamic_connectivity(db.iloc[subj], dynamics, win_length, win_step)
                coeffs = stats.fit_states(d_rs, states)
                all_coeffs.append(coeffs)

            X_dynamics = np.vstack(all_coeffs)

        # compose X out of the appropriate matricies
        try:
            del X # resets X for each fold
        except:
            pass

        for features in ['X_xcorr', 'X_conn', 'X_stat', 'X_dynamics', 'X_raw']:
            if features in vars():
                if 'X' in vars():
                    X = np.hstack((X, eval(features)))
                else:
                    X = eval(features)
        try:
            logger.info('X features size {}'.format(X.shape))
        except:
            logger.error('X not defined: no suitable predictors specified')
            sys.exit(1)

        X_train = X[train_idx, :]
        X_test = X[test_idx, :]

        if select:
            n_select = int(round(select*X_train.shape[0]))
            X_train, X_test = stats.feature_select(X_train, y_train, X_test, n=n_select)

        # diagnostics are run on the first fold only
        if diagnostics and count == 1:
            if len(y_raw.shape) == 1:
                y_raw = y_raw[train_idx]
            else:
                y_raw = y_raw[train_idx, :]
            stats.diagnostics(X_train, X_test, y_train, y_test, y_raw, output)

        # TODO: for large numbers of features, impossible to read output
        stats.plot_X(X_train, os.path.join(output, 'xbrain_X_test-vs-train.pdf'), X2=X_test)

        # control experiment: y is random, classifier should perform at chance
        if shuffle_y:
            logger.debug('null experiment: shuffling y')
            y_train = np.random.permutation(y_train)
            y_test = np.random.permutation(y_test)

        # run classification including inner loop hyperparameter optimization
        try:
            results = stats.classify(X_train, X_test, y_train, y_test, method, output)
        except Exception as e:
            logger.error(e)
            sys.exit(1)

        # append the results of each fold
        acc.append(results['accuracy'])
        rec.append(results['recall'])
        prec.append(results['precision'])
        f1.append(results['f1'])
        auc.append(results['auc'])

        # record the predicted/correct values in the same order as database
        y_predictions[test_idx] = results['y_test_pred']
        y_actual[test_idx] = y_test

        writer(csv_results, '{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}\n'.format(
            count,
            results['accuracy'][0],results['accuracy'][1],
            results['recall'][0], results['recall'][1], results['recall'][2], results['recall'][3],
            results['precision'][0], results['precision'][1], results['precision'][2], results['precision'][3],
            results['f1'][0], results['f1'][1], results['f1'][2], results['f1'][3],
            results['auc'][0], results['auc'][1], results['auc'][2], results['auc'][3],
            results['n_features_retained']))
        count += 1

        # collects the relevant hyperparameters for the chosen model
        hp_tmp = results['hp_dict']
        for hp in hp_tmp.keys():
            hp_dict[hp].append(hp_tmp[hp])
        writer(csv_hyper, str(hp_dict))

    # hyperparameters found during inner loop cross validation
    hp_final = {}
    for hp in hp_dict.keys():
        if isinstance(hp_dict[hp][0][0], basestring):
            # categorical hyperparameters, take most frequent
            hp_final[hp] = mode(hp_dict[hp][0])[0][0]
        else:
            # continuous / integet hyperparameters, take median
            hp_final[hp] = np.median(hp_dict[hp][0])
    logger.info('final hyperparameters:\n{}'.format(hp_final))
    writer(csv_hyper, str(hp_final))

    # store predictions, actual values, in reduced database
    db['y_actual'] = y_actual
    db['y_predictions'] = y_predictions
    db.to_csv(os.path.join(output, 'xbrain_database.csv'), index=False)

    # final results
    acc = parse_results(acc)
    acc_train_mean = acc[0][0]
    acc_train_sem = acc[0][1]
    acc_test_mean = acc[1][0]
    acc_test_sem = acc[1][1]

    rec = parse_results(rec)
    rec_train_macro_mean = rec[0][0]
    rec_train_macro_sem = rec[0][1]
    rec_test_macro_mean = rec[1][0]
    rec_test_macro_sem = rec[1][1]
    rec_train_micro_mean = rec[2][0]
    rec_train_micro_sem = rec[2][1]
    rec_test_micro_mean = rec[3][0]
    rec_test_micro_sem = rec[3][1]

    prec = parse_results(prec)
    prec_train_macro_mean = prec[0][0]
    prec_train_macro_sem = prec[0][1]
    prec_test_macro_mean = prec[1][0]
    prec_test_macro_sem = prec[1][1]
    prec_train_micro_mean = prec[2][0]
    prec_train_micro_sem = prec[2][1]
    prec_test_micro_mean = prec[3][0]
    prec_test_micro_sem = prec[3][1]

    f1 = parse_results(f1)
    f1_train_macro_mean = f1[0][0]
    f1_train_macro_sem = f1[0][1]
    f1_test_macro_mean = f1[1][0]
    f1_test_macro_sem = f1[1][1]
    f1_train_micro_mean = f1[2][0]
    f1_train_micro_sem = f1[2][1]
    f1_test_micro_mean = f1[3][0]
    f1_test_micro_sem = f1[3][1]

    auc = parse_results(auc)
    auc_train_macro_mean = auc[0][0]
    auc_train_macro_sem = auc[0][1]
    auc_test_macro_mean = auc[1][0]
    auc_test_macro_sem = auc[1][1]
    auc_train_micro_mean = auc[2][0]
    auc_train_micro_sem = auc[2][1]
    auc_test_micro_mean = auc[3][0]
    auc_test_micro_sem = auc[3][1]

    writer(csv_results, 'mean,{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},n/a\n'.format(
        acc_train_mean, acc_test_mean,
        rec_train_macro_mean, rec_test_macro_mean, rec_train_micro_mean, rec_test_micro_mean,
        prec_train_macro_mean, prec_test_macro_mean, prec_train_micro_mean, prec_test_micro_mean,
        f1_train_macro_mean, f1_test_macro_mean, f1_train_micro_mean, f1_test_micro_mean,
        auc_train_macro_mean, auc_test_macro_mean, auc_train_micro_mean, auc_test_micro_mean))

    writer(csv_results, 'sem,{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},n/a'.format(
        acc_train_sem, acc_test_sem,
        rec_train_macro_sem, rec_test_macro_sem, rec_train_micro_sem, rec_test_micro_sem,
        prec_train_macro_sem, prec_test_macro_sem, prec_train_micro_sem, prec_test_micro_sem,
        f1_train_macro_sem, f1_test_macro_sem, f1_train_micro_sem, f1_test_micro_sem,
        auc_train_macro_sem, auc_test_macro_sem, auc_train_micro_sem, auc_test_micro_sem))

    if not diagnostics:
        csv_hyper.close()
        csv_info.close()
        csv_results.close()

    final_results = {}
    final_results['mean'] = [acc_train_mean, acc_test_mean,
        rec_train_macro_mean, rec_test_macro_mean, rec_train_micro_mean, rec_test_micro_mean,
        prec_train_macro_mean, prec_test_macro_mean, prec_train_micro_mean, prec_test_micro_mean,
        f1_train_macro_mean, f1_test_macro_mean, f1_train_micro_mean, f1_test_micro_mean,
        auc_train_macro_mean, auc_test_macro_mean, auc_train_micro_mean, auc_test_micro_mean]
    final_results['sem'] = [acc_train_sem, acc_test_sem,
        rec_train_macro_sem, rec_test_macro_sem, rec_train_micro_sem, rec_test_micro_sem,
        prec_train_macro_sem, prec_test_macro_sem, prec_train_micro_sem, prec_test_micro_sem,
        f1_train_macro_sem, f1_test_macro_sem, f1_train_micro_sem, f1_test_micro_sem,
        auc_train_macro_sem, auc_test_macro_sem, auc_train_micro_sem, auc_test_micro_sem]

    logger.info('train results:\n  acc={}+/-{}\n  f1={}+/-{}\n  auc={}+/-{}'.format(
        acc_train_mean, acc_train_sem, f1_train_macro_mean, f1_train_macro_sem, auc_train_macro_mean, auc_train_macro_sem))
    logger.info('test results:\n  acc={}+/-{}\n  f1={}+/-{}\n  auc={}+/-{}'.format(
        acc_test_mean, acc_test_sem, f1_test_macro_mean, f1_test_macro_sem, auc_test_macro_mean, auc_test_macro_sem))


    return(final_results)

if __name__ == '__main__':
    arguments = docopt(__doc__)

    # utility functions
    debug         = arguments['--debug']
    output        = arguments['--output']
    iterations    = int(arguments['--iterations'])

    # debug is very noisy
    logger.info('starting')
    if debug:
        logger.setLevel(logging.DEBUG)
    else:
        logger.setLevel(logging.INFO)

    output = assert_output(output)

    if not arguments['--diagnostics']:
        csv_mean = open(os.path.join(output, 'xbrain_results_final_mean.csv'),  'wb')
        csv_sem = open(os.path.join(output, 'xbrain_results_final_sem.csv'),  'wb')
        header = ','.join([
            'i', 'accuracy_train', 'accuracy_test',
            'recall_train_macro', 'recall_test_macro', 'recall_train_micro', 'recall_test_micro',
            'precision_train_macro', 'precision_test_macro', 'precision_train_micro', 'precision_test_micro',
            'f1_train_macro', 'f1_test_macro', 'f1_train_micro', 'f1_test_micro',
            'auc_train_macro', 'auc_test_macro', 'auc_train_micro', 'auc_test_micro\n'])
        writer(csv_mean, header)
        writer(csv_sem, header)

    for i in range(iterations):
        logger.info('beginning iteration {}/{}'.format(i+1, iterations))
        results = main(arguments, output, i)

        if not arguments['--diagnostics']:
            writer(csv_mean, '{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}\n'.format(
                i+1, results['mean'][0], results['mean'][1],
                results['mean'][2], results['mean'][3], results['mean'][4], results['mean'][5],
                results['mean'][6], results['mean'][7], results['mean'][8], results['mean'][9],
                results['mean'][10], results['mean'][11], results['mean'][12], results['mean'][13],
                results['mean'][14], results['mean'][15], results['mean'][16], results['mean'][17]))
            writer(csv_sem, '{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}\n'.format(
                i+1, results['sem'][0], results['sem'][1],
                results['sem'][2], results['sem'][3], results['sem'][4], results['sem'][5],
                results['sem'][6], results['sem'][7], results['sem'][8], results['sem'][9],
                results['sem'][10], results['sem'][11], results['sem'][12], results['sem'][13],
                results['sem'][14], results['sem'][15], results['sem'][16], results['sem'][17]))

    if not arguments['--diagnostics']:
        csv_mean.close()
        csv_sem.close()

